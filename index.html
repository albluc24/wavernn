<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" type="text/css" href="style.css">
    <title>Recurrent Neural Network based Neural Vocoders</title>
</head>
<body>
    <header>
        <p>The page contains samples generated using a trained WaveRNN based neural vocoder, which predicts a raw waveform from a mel-spectrogram.<br>
        The code to train the model can be found at the following link <a href="https://github.com/anandaswarup/waveRNN/">https://github.com/anandaswarup/waveRNN/</a>
        </p>
        <hr>
    </header>
    <main>
	    <p>Dataset: <a href="https://keithito.com/LJ-Speech-Dataset/"> LJSpeech </a> <br>
	    11790 wav files (~23 hrs) was used for training; while 1310 wav files were held out for evaluation. <br>
	    Few of the samples are given below.
	    </p>
	    <table>
		    <thread>
		    	<th> Original </th>
		    	<th> Generated </th>
		    </thread>
		    <tbody>
			    <tr>
				    <td><audio src="https://github.com/anandaswarup/waveRNN/blob/gh-pages/samples/orig/LJ001-0009.wav?raw=true" controls preload></audio></td>
				    <td><audio src="https://github.com/anandaswarup/waveRNN/blob/gh-pages/samples/gen/model_step000200000_LJ001-0009.wav?raw=true" controls preload></audio></td>
		    </tbody>
	    </table>

    </main>
</body>
</html>
